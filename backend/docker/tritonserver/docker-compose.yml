version: '3.8'

services:
  triton:
    container_name: triton_cont
    image: triton_img
    restart: on-failure
    volumes:
      - ${PWD}/model_repository:/models
    build: 
      context: .
      dockerfile: Dockerfile
      shm_size: 512m
    shm_size: 512m
    ports:
      - 8000:8000
      - 8001:8001
      - 8002:8002
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         count: 1
    #         capabilities: [gpu]
    entrypoint: /bin/sh -c "tritonserver --model-repository=/models"
